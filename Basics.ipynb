{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building A Database For Crime Reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will use Postgres to build a database for storing data about crimes that occurred in Boston. The dataset is available in the file boston.csv.\n",
    "\n",
    "We will create a database named crimes_db, with a schema named crimes, and a table named boston_crimes with data from the boston.csv file. We will also create readonly and readwrite groups with appropriate priviledges, as well as example users for each of these groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Crime Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by creating the database for storing our crime data, as well as the schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crime_db does not exist yet, so we connect to postgres db first and create the crime_db from there.\n",
    "conn = psycopg2.connect(dbname=\"postgres\", user=\"postgres\")\n",
    "conn.autocommit = True\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"CREATE DATABASE crime_db;\")\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to crime_db and create schema named crimes.\n",
    "conn = psycopg2.connect(dbname=\"crime_db\", user=\"postgres\")\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"CREATE SCHEMA crimes;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining the Column Names and Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we load data into our table, let's first understand the crime dataset so we can choose the right datatypes to use in our table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Headers:  ['incident_number', 'offense_code', 'description', 'date', 'day_of_the_week', 'lat', 'long']\n",
      "First Data Row:  ['1', '619', 'LARCENY ALL OTHERS', '2018-09-02', 'Sunday', '42.35779134', '-71.13937053']\n"
     ]
    }
   ],
   "source": [
    "with open(\"boston.csv\", \"r\") as file:\n",
    "    row_list = list(csv.reader(file))\n",
    "    \n",
    "col_headers = row_list[0]\n",
    "first_row = row_list[1]\n",
    "\n",
    "print(\"Column Headers: \", col_headers)\n",
    "print(\"First Data Row: \", first_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an Auxiliary Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a function -- get_col_set() -- that will help us identify proper datatypes for the columns. This function will return a set of all distinct values in a column of a CSV file. This will allow us to see if any columns can be of enumerated type and will allow us to easily calculate the maximum length of data in column so we can appropriately set VARCHAR.\n",
    "\n",
    "We will start off by using this function to find the number of different values in each column of the boston.csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col_set(csv_filename, col_index):\n",
    "    unique_values = set()\n",
    "    \n",
    "    with open(csv_filename, 'r') as file:\n",
    "        file_list = list(csv.reader(file))\n",
    "        for item in file_list[1:]:\n",
    "            unique_values.add(item[col_index])\n",
    "    \n",
    "    return unique_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[298329, 219, 239, 1177, 7, 18177, 18177]\n"
     ]
    }
   ],
   "source": [
    "num_distinct_values = []\n",
    "for index in range(0, len(col_headers)):\n",
    "    num_distinct_values.append(len(get_col_set(\"boston.csv\", index)))\n",
    "    \n",
    "print(num_distinct_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
